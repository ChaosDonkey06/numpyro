{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world datasets often contain many missing values. In those situations, we have to either remove those missing data (also known as \"complete case\") or replace them by some values. Though complete case is pretty straightforward, it is only applicable when the number of missing entries is small, so throwing away those entries would not affect much the power of the analysis we are conducting on the data. The second strategy, also known as [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)), is more applicable and will be our focus in this tutorial.\n",
    "\n",
    "Probably the most popular way to perform imputation is to fill a missing value with the mean, median, or mode of its corresponding feature. In that case, we implicitly assume that the feature containing missing values has no correlation with the remaining features of our dataset. This is a pretty strong assumption and might not be true in general. In addition, it does not encode any uncertainty that we might put on those values. So it is natural to think of a *Bayesian* setting to resolve those issues.\n",
    "\n",
    "In particular, given a model on the dataset, we will\n",
    "+ create a generative model for the feature with missing value\n",
    "+ and consider missing values as unobserved latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need some imports\n",
    "import numpy as onp\n",
    "import pandas as pd\n",
    "\n",
    "from jax import numpy as np, ops, random\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken from [this kaggle competition](https://www.kaggle.com/c/titanic). It contains information of passengers in the Titanic such as name, age, gender,... Our target is to predict if that person is more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv\")\n",
    "train_df.info()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data info, we know that there are missing data at `Age`, `Cabin`, and `Embarked` columns. Although `Cabin` is an important feature (because the position of a cabin in the ship can affect the chance of people in that cabin to survive), we will skip it in this tutorial for simplicity. There are many categorical columns and two numerical columns `Age` and `Fare`. Let's first look at the distribution of those categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n",
      "\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n",
      "\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]:\n",
    "    print(train_df[col].value_counts(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will merge rare groups in `SibSp` and `Parch` columns together. In addition, we'll fill 2 missing entries in `Embarked` by the mode `S`. Note that we can make a generative model for those missing entries in `Embarked` but let's skip doing so for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_df.copy()\n",
    "d.SibSp.clip(0, 1, inplace=True)\n",
    "d.Parch.clip(0, 2, inplace=True)\n",
    "d.Embarked.fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data, we can observe that each name contains a title. We know that age is correlated with the title of the name: e.g. those with Mrs. would be older than those with `Miss.` (in average) so it might be good to create that feature. Let's look at the distribution of each title first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.          517\n",
       "Miss.        182\n",
       "Mrs.         125\n",
       "Master.       40\n",
       "Dr.            7\n",
       "Rev.           6\n",
       "Major.         2\n",
       "Mlle.          2\n",
       "Col.           2\n",
       "Mme.           1\n",
       "Lady.          1\n",
       "Don.           1\n",
       "Jonkheer.      1\n",
       "Capt.          1\n",
       "the            1\n",
       "Sir.           1\n",
       "Ms.            1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a new column `Title`, where rare titles are merged into one group `Misc.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Title\"] = d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).apply(\n",
    "    lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is ready to turn the dataframe, which includes categorical values, into numpy arrays. We also perform standardization (a good practice for regression models) for `Age` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cat = pd.CategoricalDtype(categories=[\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\", \"Misc.\"], ordered=True)\n",
    "embarked_cat = pd.CategoricalDtype(categories=[\"S\", \"C\", \"Q\"], ordered=True)\n",
    "age_mean, age_std = d.Age.mean(), d.Age.std()\n",
    "data = dict(age=d.Age.pipe(lambda x: (x - age_mean) / age_std).values,\n",
    "            pclass=d.Pclass.values - 1,\n",
    "            title=d.Title.astype(title_cat).cat.codes.values,\n",
    "            sex=(d.Sex == \"male\").astype(int).values,\n",
    "            sibsp=d.SibSp.values,\n",
    "            parch=d.Parch.values,\n",
    "            embarked=d.Embarked.astype(embarked_cat).cat.codes.values,\n",
    "            survived=d.Survived.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we would like to talk a bit about how to define improper priors in NumPyro. Consider the following logistic regression model,\n",
    "```python\n",
    "def model(x, y):\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    b = numpyro.param(\"b\", dist.Normal(0, 1))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    numpyro.sample(\"obs\", dist.Normal(a + b * x, sigma), obs=y)\n",
    "```\n",
    ". There we have some priors on sites `a`, `b`, and `sigma`. Now, assume that there is no apriori information on those sites, how can we define and get posterior samples of `a`, `b`, and `sigma`? In NumPyro, we can do it with `numpyro.param` primitives. An MCMC kernel will treat all `param` sites as they are having improper priors. For example, a corresponding linear regression model with no prior information is\n",
    "```python\n",
    "def model(x, y):\n",
    "    a = numpyro.param(\"a\", 0)\n",
    "    b = numpyro.param(\"b\", 1)\n",
    "    sigma = numpyro.param(\"sigma\", 1, constraint=constraints.positive)\n",
    "    numpyro.sample(\"obs\", dist.Normal(a + b * x, sigma), obs=y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another remark is: in MCMC context, the following models\n",
    "```python\n",
    "def model1():\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "```\n",
    "and\n",
    "```python\n",
    "def model2():\n",
    "    a = numpyro.param(\"a\", 0)\n",
    "    numpyro.sample(\"a_obs\", dist.Normal(0, 1), obs=a)\n",
    "```\n",
    "are equivalent because both of them have\n",
    "+ the same latent sites `a`,\n",
    "+ and the same log densities `dist.Normal(0, 1).log_prob(a)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With those remarks in mind, we are ready to define a logistic regression model to predict survival chance given passengers' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(age, pclass, title, sex, sibsp, parch, embarked, survived=None):\n",
    "    b_pclass = numpyro.sample(\"b_Pclass\", dist.Normal(0, 1), sample_shape=(3,))\n",
    "    b_title = numpyro.sample(\"b_Title\", dist.Normal(0, 1), sample_shape=(5,))\n",
    "    b_sex = numpyro.sample(\"b_Sex\", dist.Normal(0, 1), sample_shape=(2,))\n",
    "    b_sibsp = numpyro.sample(\"b_SibSp\", dist.Normal(0, 1), sample_shape=(2,))\n",
    "    b_parch = numpyro.sample(\"b_Parch\", dist.Normal(0, 1), sample_shape=(3,))\n",
    "    b_embarked = numpyro.sample(\"b_Embarked\", dist.Normal(0, 1), sample_shape=(3,))\n",
    "\n",
    "    # impute age by Title\n",
    "    age_mu = numpyro.sample(\"age_mu\", dist.Normal(0, 1), sample_shape=(5,))\n",
    "    age_mu = age_mu[title]\n",
    "    age_sigma = numpyro.sample(\"age_sigma\", dist.Normal(0, 1), sample_shape=(5,))\n",
    "    age_sigma = age_sigma[title]\n",
    "    age_isnan = onp.isnan(age)\n",
    "    age_nanidx = onp.nonzero(age_isnan)[0]\n",
    "    if survived is not None:\n",
    "        age_impute = numpyro.param(\"age_impute\", np.zeros(age_isnan.sum()))\n",
    "    else:  # we are making prediction\n",
    "        age_impute = numpyro.sample(\"age_impute\", dist.Normal(age_mu[age_nanidx], age_sigma[age_nanidx]))\n",
    "    age = ops.index_update(age, age_nanidx, age_impute)\n",
    "    numpyro.sample(\"age\", dist.Normal(age_mu, age_sigma), obs=age)\n",
    "\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    b_age = numpyro.sample(\"b_Age\", dist.Normal(0, 1))\n",
    "    logits = a + b_age * age\n",
    "\n",
    "    logits = logits + b_title[title] + b_pclass[pclass] + b_sex[sex] \\\n",
    "        + b_sibsp[sibsp] + b_parch[parch] + b_embarked[embarked]\n",
    "    if survived is None:\n",
    "        probs = expit(logits)\n",
    "        # record `probs` value in prediction\n",
    "        numpyro.sample(\"probs\", dist.Delta(probs))\n",
    "    numpyro.sample(\"survived\", dist.Bernoulli(logits=logits), obs=survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the model, the prior for `age` is `dist.Normal(age_mu, age_sigma)`, where the values of `age_mu` and `age_sigma` depend on `title`. Because there are missing values in `age`, we will encode those missing values in the latent parameter `age_impute`. Then we can replace `NaN` entries in `age` with the vector `age_impute`. Under the hood, similar to `model2` in the above remark, `age_impute` will have prior `dist.Normal(age_mu, age_sigma)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MCMC with NUTS kernel to sample both regression coefficients and imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:24<00:00, 82.85it/s, 63 steps of size 7.21e-02. acc. prob=0.93]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "              a      0.11      0.83      0.12     -1.30      1.40    944.52      1.00\n",
      "  age_impute[0]      0.24      0.84      0.21     -1.12      1.58   1984.52      1.00\n",
      "  age_impute[1]     -0.11      0.88     -0.13     -1.57      1.42   2241.81      1.00\n",
      "  age_impute[2]      0.37      0.82      0.38     -0.96      1.71   2613.78      1.00\n",
      "  age_impute[3]      0.25      0.83      0.25     -1.22      1.47   1635.84      1.00\n",
      "  age_impute[4]     -0.69      0.92     -0.64     -2.24      0.77   3847.56      1.00\n",
      "  age_impute[5]      0.22      0.90      0.21     -1.30      1.64   3948.63      1.00\n",
      "  age_impute[6]      0.42      0.80      0.42     -0.86      1.74   2173.52      1.00\n",
      "  age_impute[7]     -0.65      0.88     -0.64     -2.16      0.73   2593.56      1.00\n",
      "  age_impute[8]     -0.13      0.90     -0.13     -1.46      1.49   3222.07      1.00\n",
      "  age_impute[9]      0.23      0.86      0.24     -1.12      1.69   2927.42      1.00\n",
      " age_impute[10]      0.20      0.89      0.19     -1.21      1.69   2529.10      1.00\n",
      " age_impute[11]      0.22      0.92      0.19     -1.26      1.72   2161.66      1.00\n",
      " age_impute[12]     -0.65      0.83     -0.65     -2.05      0.68   1955.29      1.00\n",
      " age_impute[13]      0.22      0.89      0.23     -1.19      1.68   2227.36      1.00\n",
      " age_impute[14]      0.00      0.91      0.01     -1.50      1.40   2301.04      1.00\n",
      " age_impute[15]      0.40      0.85      0.40     -0.98      1.83   1783.46      1.00\n",
      " age_impute[16]     -1.73      0.26     -1.73     -2.16     -1.28   1831.27      1.00\n",
      " age_impute[17]      0.21      0.88      0.17     -1.35      1.60   2915.85      1.00\n",
      " age_impute[18]      0.21      0.82      0.18     -1.02      1.56   1856.86      1.00\n",
      " age_impute[19]     -0.65      0.88     -0.65     -2.11      0.76   1203.00      1.00\n",
      " age_impute[20]      0.22      0.91      0.22     -1.36      1.62   1622.05      1.00\n",
      " age_impute[21]      0.20      0.92      0.23     -1.24      1.67   2048.48      1.00\n",
      " age_impute[22]      0.21      0.90      0.22     -1.29      1.60   2183.51      1.00\n",
      " age_impute[23]     -0.14      0.92     -0.19     -1.60      1.36   2641.03      1.00\n",
      " age_impute[24]     -0.70      0.98     -0.66     -2.27      0.93   1917.24      1.00\n",
      " age_impute[25]      0.16      0.85      0.16     -1.29      1.47   2589.66      1.00\n",
      " age_impute[26]      0.22      0.93      0.20     -1.26      1.70   1886.75      1.00\n",
      " age_impute[27]     -0.72      0.86     -0.71     -2.17      0.63   1591.14      1.00\n",
      " age_impute[28]      0.58      0.74      0.59     -0.57      1.83   1881.63      1.00\n",
      " age_impute[29]      0.22      0.87      0.21     -1.29      1.53   2254.44      1.00\n",
      " age_impute[30]      0.21      0.89      0.21     -1.13      1.73   2580.13      1.00\n",
      " age_impute[31]     -1.71      0.24     -1.72     -2.07     -1.28   1670.25      1.00\n",
      " age_impute[32]      0.42      0.83      0.40     -0.81      1.83   2036.85      1.00\n",
      " age_impute[33]      0.30      0.83      0.33     -1.12      1.61   1931.17      1.00\n",
      " age_impute[34]     -1.72      0.27     -1.73     -2.14     -1.27   2010.65      1.00\n",
      " age_impute[35]     -0.46      0.88     -0.46     -1.99      0.87   1448.56      1.00\n",
      " age_impute[36]      0.27      0.88      0.29     -0.99      1.94   1784.35      1.00\n",
      " age_impute[37]      0.33      0.88      0.33     -1.06      1.83   1927.76      1.00\n",
      " age_impute[38]      0.36      0.77      0.36     -0.84      1.65   2324.12      1.00\n",
      " age_impute[39]      0.22      0.87      0.21     -1.20      1.61   2321.48      1.00\n",
      " age_impute[40]     -0.66      0.82     -0.66     -1.99      0.62   2310.79      1.00\n",
      " age_impute[41]      0.20      0.86      0.21     -1.19      1.47   1813.34      1.00\n",
      " age_impute[42]      0.20      0.85      0.22     -1.25      1.43   2313.58      1.00\n",
      " age_impute[43]      0.20      0.90      0.23     -1.13      1.90   2806.31      1.00\n",
      " age_impute[44]     -0.42      0.87     -0.40     -1.80      1.07   2518.61      1.00\n",
      " age_impute[45]     -0.35      0.91     -0.34     -1.82      1.09   2369.09      1.00\n",
      " age_impute[46]     -0.32      0.94     -0.29     -1.95      1.11   1946.10      1.00\n",
      " age_impute[47]     -0.69      0.92     -0.70     -2.17      0.83   1713.98      1.00\n",
      " age_impute[48]      0.20      0.91      0.19     -1.19      1.74   1842.93      1.00\n",
      " age_impute[49]      0.38      0.84      0.36     -1.06      1.74   2962.56      1.00\n",
      " age_impute[50]      0.24      0.86      0.24     -1.02      1.83   2014.81      1.00\n",
      " age_impute[51]     -0.33      0.95     -0.34     -1.89      1.26   2935.95      1.00\n",
      " age_impute[52]      0.31      0.81      0.32     -0.96      1.69   2244.80      1.00\n",
      " age_impute[53]     -0.68      0.83     -0.66     -1.84      0.83   2762.35      1.00\n",
      " age_impute[54]      0.22      0.83      0.25     -1.06      1.56   2252.35      1.00\n",
      " age_impute[55]      0.34      0.89      0.29     -1.05      1.79   2177.11      1.00\n",
      " age_impute[56]      0.34      0.92      0.33     -0.98      1.99   3084.61      1.00\n",
      " age_impute[57]     -0.03      0.87      0.00     -1.47      1.29   2148.87      1.00\n",
      " age_impute[58]     -0.64      0.91     -0.62     -2.30      0.73   2342.99      1.00\n",
      " age_impute[59]     -0.15      0.86     -0.14     -1.65      1.17   1381.53      1.00\n",
      " age_impute[60]     -0.61      0.93     -0.62     -2.10      0.83   3351.25      1.00\n",
      " age_impute[61]      0.21      0.87      0.24     -1.16      1.65   1680.49      1.00\n",
      " age_impute[62]     -0.57      0.83     -0.54     -1.91      0.80   1467.52      1.00\n",
      " age_impute[63]      0.22      0.92      0.21     -1.16      1.77   2832.82      1.00\n",
      " age_impute[64]     -0.69      0.89     -0.66     -2.12      0.72   2105.35      1.00\n",
      " age_impute[65]      0.39      0.79      0.39     -0.86      1.75   1915.62      1.00\n",
      " age_impute[66]      0.23      0.87      0.24     -1.05      1.78   3359.66      1.00\n",
      " age_impute[67]      0.29      0.84      0.30     -1.00      1.76   1750.04      1.00\n",
      " age_impute[68]      0.33      0.90      0.34     -1.21      1.74   1977.47      1.00\n",
      " age_impute[69]      0.24      0.87      0.26     -1.09      1.69   2614.97      1.00\n",
      " age_impute[70]     -0.66      0.87     -0.65     -2.06      0.76   1841.96      1.00\n",
      " age_impute[71]     -0.65      0.86     -0.61     -1.98      0.73   2092.89      1.00\n",
      " age_impute[72]      0.22      0.90      0.22     -1.08      1.86   1878.48      1.00\n",
      " age_impute[73]      0.38      0.81      0.37     -0.99      1.59   1981.92      1.00\n",
      " age_impute[74]     -0.65      0.87     -0.68     -2.12      0.69   1980.53      1.00\n",
      " age_impute[75]      0.39      0.80      0.39     -0.95      1.69   2818.52      1.00\n",
      " age_impute[76]      0.20      0.91      0.19     -1.19      1.89   2244.62      1.00\n",
      " age_impute[77]      0.24      0.87      0.22     -1.10      1.66   2880.76      1.00\n",
      " age_impute[78]     -0.38      0.90     -0.39     -1.88      1.09   2862.13      1.00\n",
      " age_impute[79]      0.22      0.92      0.22     -1.47      1.59   1707.99      1.00\n",
      " age_impute[80]      0.22      0.93      0.25     -1.44      1.64   3313.13      1.00\n",
      " age_impute[81]      0.22      0.89      0.22     -1.25      1.65   3784.31      1.00\n",
      " age_impute[82]      0.59      0.82      0.56     -0.84      1.80   2436.13      1.00\n",
      " age_impute[83]      0.24      0.83      0.27     -1.23      1.57   2035.53      1.00\n",
      " age_impute[84]      0.21      0.88      0.22     -1.13      1.75   2123.79      1.00\n",
      " age_impute[85]      0.24      0.88      0.27     -1.28      1.53   1550.25      1.00\n",
      " age_impute[86]      0.32      0.79      0.32     -0.99      1.66   2440.07      1.00\n",
      " age_impute[87]     -0.11      0.87     -0.11     -1.46      1.39   2956.82      1.00\n",
      " age_impute[88]      0.19      0.88      0.19     -1.09      1.82   3220.38      1.00\n",
      " age_impute[89]      0.23      0.92      0.26     -1.16      1.88   2209.51      1.00\n",
      " age_impute[90]      0.43      0.76      0.45     -0.93      1.53   2241.41      1.00\n",
      " age_impute[91]      0.21      0.93      0.23     -1.35      1.64   3937.91      1.00\n",
      " age_impute[92]      0.20      0.83      0.20     -1.18      1.57   1531.83      1.00\n",
      " age_impute[93]      0.27      0.90      0.27     -1.20      1.68   3563.13      1.00\n",
      " age_impute[94]      0.23      0.87      0.22     -1.23      1.64   2711.33      1.00\n",
      " age_impute[95]      0.23      0.83      0.23     -1.16      1.65   2301.97      1.00\n",
      " age_impute[96]      0.35      0.88      0.33     -1.19      1.75   2147.71      1.00\n",
      " age_impute[97]      0.25      0.91      0.24     -1.17      1.76   1706.43      1.00\n",
      " age_impute[98]     -0.41      0.91     -0.42     -1.76      1.18   1952.16      1.00\n",
      " age_impute[99]      0.20      0.86      0.20     -1.19      1.55   2757.55      1.00\n",
      "age_impute[100]      0.22      0.86      0.21     -1.18      1.65   2148.98      1.00\n",
      "age_impute[101]      0.20      0.90      0.19     -1.14      1.75   2448.20      1.00\n",
      "age_impute[102]     -0.32      0.91     -0.32     -1.89      1.08   1968.22      1.00\n",
      "age_impute[103]     -0.01      0.87     -0.02     -1.57      1.29   2623.23      1.00\n",
      "age_impute[104]      0.24      0.84      0.27     -1.07      1.57   3218.07      1.00\n",
      "age_impute[105]      0.22      0.87      0.25     -1.04      1.72   2074.73      1.00\n",
      "age_impute[106]      0.23      0.93      0.23     -1.39      1.71   2227.99      1.00\n",
      "age_impute[107]      0.23      0.85      0.25     -1.12      1.60   2516.61      1.00\n",
      "age_impute[108]      0.32      0.85      0.31     -1.13      1.60   3244.30      1.00\n",
      "age_impute[109]      0.23      0.84      0.23     -1.33      1.40   2813.03      1.00\n",
      "age_impute[110]      0.31      0.74      0.31     -0.95      1.41   2038.12      1.00\n",
      "age_impute[111]      0.21      0.90      0.20     -1.37      1.51   3030.98      1.00\n",
      "age_impute[112]     -0.04      0.88     -0.06     -1.27      1.64   2617.68      1.00\n",
      "age_impute[113]      0.22      0.84      0.20     -1.16      1.65   2300.83      1.00\n",
      "age_impute[114]      0.35      0.86      0.34     -0.83      1.95   2466.52      1.00\n",
      "age_impute[115]      0.21      0.88      0.20     -1.26      1.52   2872.10      1.00\n",
      "age_impute[116]      0.20      0.86      0.19     -1.08      1.77   3148.82      1.00\n",
      "age_impute[117]     -0.32      0.93     -0.30     -1.81      1.16   1917.79      1.00\n",
      "age_impute[118]      0.22      0.87      0.23     -1.23      1.62   2173.01      1.00\n",
      "age_impute[119]     -0.63      0.91     -0.61     -2.15      0.89   2176.65      1.00\n",
      "age_impute[120]      0.63      0.76      0.61     -0.64      1.81   2180.45      1.00\n",
      "age_impute[121]      0.21      0.92      0.23     -1.37      1.63   1905.46      1.00\n",
      "age_impute[122]      0.23      0.86      0.22     -1.26      1.51   2596.07      1.00\n",
      "age_impute[123]     -0.40      0.92     -0.39     -1.91      1.09   2769.70      1.00\n",
      "age_impute[124]     -0.62      0.90     -0.62     -2.11      0.83   2443.32      1.00\n",
      "age_impute[125]      0.22      0.89      0.19     -1.26      1.59   3873.17      1.00\n",
      "age_impute[126]      0.23      0.85      0.23     -1.13      1.58   2246.85      1.00\n",
      "age_impute[127]      0.31      0.82      0.29     -0.91      1.83   1806.39      1.00\n",
      "age_impute[128]      0.18      0.92      0.18     -1.39      1.61   2679.99      1.00\n",
      "age_impute[129]     -0.69      0.89     -0.71     -2.19      0.71   3033.33      1.00\n",
      "age_impute[130]      0.22      0.86      0.21     -1.16      1.58   2166.98      1.00\n",
      "age_impute[131]      0.22      0.85      0.25     -1.19      1.62   1885.36      1.00\n",
      "age_impute[132]      0.36      0.90      0.35     -1.14      1.85   1716.33      1.00\n",
      "age_impute[133]      0.24      0.91      0.25     -1.32      1.70   2297.68      1.00\n",
      "age_impute[134]     -0.10      0.87     -0.13     -1.55      1.34   2846.41      1.00\n",
      "age_impute[135]      0.21      0.87      0.22     -1.30      1.54   3119.36      1.00\n",
      "age_impute[136]      0.21      0.84      0.21     -1.23      1.51   2713.22      1.00\n",
      "age_impute[137]     -0.66      0.85     -0.64     -2.01      0.75   2864.87      1.00\n",
      "age_impute[138]      0.17      0.83      0.17     -1.18      1.55   2261.80      1.00\n",
      "age_impute[139]      0.21      0.92      0.18     -1.27      1.70   2695.22      1.00\n",
      "age_impute[140]      0.38      0.77      0.36     -0.79      1.66   1692.36      1.00\n",
      "age_impute[141]      0.26      0.90      0.26     -1.31      1.62   1925.46      1.00\n",
      "age_impute[142]     -0.34      0.87     -0.34     -1.74      1.14   3031.30      1.00\n",
      "age_impute[143]     -0.11      0.93     -0.08     -1.62      1.43   2894.04      1.00\n",
      "age_impute[144]     -0.68      0.89     -0.61     -2.26      0.62   3112.89      1.00\n",
      "age_impute[145]     -1.74      0.27     -1.74     -2.21     -1.32   2742.27      1.00\n",
      "age_impute[146]      0.31      0.86      0.30     -1.04      1.77   1619.24      1.00\n",
      "age_impute[147]      0.21      0.88      0.18     -1.09      1.80   1414.20      1.00\n",
      "age_impute[148]     -0.66      0.83     -0.67     -2.04      0.63   1631.65      1.00\n",
      "age_impute[149]      0.23      0.78      0.24     -1.07      1.49   1706.48      1.00\n",
      "age_impute[150]      0.20      0.82      0.19     -1.03      1.59   1847.65      1.00\n",
      "age_impute[151]      0.20      0.87      0.17     -1.33      1.51   2185.01      1.00\n",
      "age_impute[152]      0.00      0.87     -0.01     -1.37      1.49   2605.83      1.00\n",
      "age_impute[153]      0.22      0.82      0.22     -1.20      1.45   2955.54      1.00\n",
      "age_impute[154]      1.09      0.94      1.08     -0.54      2.50   2472.70      1.00\n",
      "age_impute[155]      0.20      0.86      0.24     -1.29      1.46   2169.25      1.00\n",
      "age_impute[156]      0.26      0.85      0.27     -1.06      1.71   2487.27      1.00\n",
      "age_impute[157]      0.21      0.89      0.22     -1.17      1.62   3149.04      1.00\n",
      "age_impute[158]      0.21      0.86      0.19     -1.24      1.57   2409.83      1.00\n",
      "age_impute[159]      0.19      0.89      0.19     -1.23      1.57   2377.32      1.00\n",
      "age_impute[160]      0.22      0.89      0.22     -1.16      1.73   2746.19      1.00\n",
      "age_impute[161]     -0.43      0.85     -0.44     -2.04      0.81   1963.26      1.00\n",
      "age_impute[162]      0.36      0.84      0.37     -0.90      1.79   2528.52      1.00\n",
      "age_impute[163]      0.33      0.85      0.33     -0.98      1.70   1952.18      1.00\n",
      "age_impute[164]      0.20      0.87      0.18     -1.18      1.56   2663.71      1.00\n",
      "age_impute[165]      0.19      0.87      0.20     -1.15      1.65   2328.12      1.00\n",
      "age_impute[166]     -0.12      0.81     -0.11     -1.46      1.12   2510.26      1.00\n",
      "age_impute[167]      0.21      0.86      0.22     -1.18      1.59   1563.05      1.00\n",
      "age_impute[168]      0.24      0.87      0.23     -1.14      1.73   4116.07      1.00\n",
      "age_impute[169]      0.04      0.83      0.05     -1.29      1.46   1742.90      1.00\n",
      "age_impute[170]      0.20      0.85      0.19     -1.32      1.47   1911.70      1.00\n",
      "age_impute[171]      0.42      0.80      0.43     -0.70      1.86   3029.40      1.00\n",
      "age_impute[172]      0.21      0.88      0.21     -1.23      1.65   2940.16      1.00\n",
      "age_impute[173]     -0.48      0.89     -0.46     -1.84      1.08   4029.66      1.00\n",
      "age_impute[174]      0.22      0.84      0.22     -1.16      1.58   2034.76      1.00\n",
      "age_impute[175]      0.17      0.82      0.19     -1.11      1.56   1662.40      1.00\n",
      "age_impute[176]     -0.46      0.92     -0.46     -1.88      1.05   2699.09      1.00\n",
      "      age_mu[0]      0.19      0.04      0.19      0.12      0.26   1621.12      1.00\n",
      "      age_mu[1]     -0.55      0.07     -0.55     -0.66     -0.43   1960.06      1.00\n",
      "      age_mu[2]      0.42      0.08      0.42      0.30      0.54   1589.54      1.00\n",
      "      age_mu[3]     -1.73      0.05     -1.73     -1.80     -1.65   1566.05      1.00\n",
      "      age_mu[4]      0.85      0.17      0.86      0.56      1.12   2679.36      1.00\n",
      "   age_sigma[0]      0.88      0.03      0.88      0.83      0.93    807.51      1.00\n",
      "   age_sigma[1]      0.90      0.05      0.90      0.82      0.99   1105.15      1.00\n",
      "   age_sigma[2]      0.79      0.06      0.79      0.70      0.88   1577.42      1.00\n",
      "   age_sigma[3]      0.26      0.03      0.25      0.21      0.31   1066.62      1.00\n",
      "   age_sigma[4]      0.93      0.14      0.92      0.70      1.14   1330.72      1.00\n",
      "          b_Age     -0.44      0.13     -0.44     -0.64     -0.22   1684.84      1.00\n",
      "  b_Embarked[0]     -0.24      0.58     -0.23     -1.17      0.73    713.88      1.00\n",
      "  b_Embarked[1]      0.34      0.58      0.36     -0.57      1.27    695.57      1.00\n",
      "  b_Embarked[2]      0.08      0.59      0.08     -0.89      1.04    737.08      1.00\n",
      "     b_Parch[0]      0.48      0.56      0.49     -0.42      1.40    673.13      1.00\n",
      "     b_Parch[1]      0.15      0.56      0.16     -0.72      1.07    768.46      1.00\n",
      "     b_Parch[2]     -0.46      0.57     -0.47     -1.44      0.45    664.74      1.00\n",
      "    b_Pclass[0]      1.20      0.56      1.22      0.34      2.18    523.53      1.00\n",
      "    b_Pclass[1]      0.05      0.55      0.09     -0.90      0.92    513.45      1.00\n",
      "    b_Pclass[2]     -1.18      0.55     -1.16     -1.98     -0.20    503.46      1.00\n",
      "       b_Sex[0]      1.11      0.71      1.11     -0.18      2.15   1173.51      1.00\n",
      "       b_Sex[1]     -1.07      0.73     -1.05     -2.14      0.16   1176.47      1.00\n",
      "     b_SibSp[0]      0.26      0.65      0.28     -0.76      1.33    882.45      1.00\n",
      "     b_SibSp[1]     -0.19      0.65     -0.18     -1.26      0.85   1000.59      1.00\n",
      "     b_Title[0]     -0.95      0.55     -0.95     -1.85     -0.09    895.58      1.00\n",
      "     b_Title[1]     -0.34      0.59     -0.33     -1.31      0.61    882.55      1.00\n",
      "     b_Title[2]      0.54      0.59      0.54     -0.49      1.44    831.26      1.00\n",
      "     b_Title[3]      1.48      0.60      1.48      0.42      2.42    939.75      1.00\n",
      "     b_Title[4]     -0.69      0.62     -0.70     -1.70      0.32   1129.18      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(NUTS(model), 1000, 1000)\n",
    "mcmc.run(random.PRNGKey(0), **data)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double check that the assumption \"age is correlated with title\" is reasonable, let's look at the infered age by title. Recall that we performed standarization on `age`, so here we need to scale back to original domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mr.': 32.411587,\n",
       " 'Miss.': 21.779383,\n",
       " 'Mrs.': 35.813175,\n",
       " 'Master.': 4.6338615,\n",
       " 'Misc.': 42.073486}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_by_title = age_mean + age_std * mcmc.get_samples()[\"age_mu\"].mean(axis=0)\n",
    "dict(zip(title_cat.categories, age_by_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The infered result confirms our assumption that `Age` is correlated with `Title`:\n",
    "+ those with `Master.` title has pretty small age (in other words, they are children in the ship) comparing to the other groups,\n",
    "+ those with `Mrs.` title have larger age than those with `Miss.` title (in average).\n",
    "\n",
    "We can also see that the result is similar to the actual statistical mean of `Age` given `Title` in our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.        32.368090\n",
       "Miss.      21.773973\n",
       "Mrs.       35.898148\n",
       "Master.     4.574167\n",
       "Misc.      42.384615\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby(\"Title\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, we have many information about the regression coefficients together with imputed values and their uncertainties. Let's inspect those results a bit:\n",
    "+ The mean value `-0.44` of `b_Age` implies that those with smaller ages have better chance to survive.\n",
    "+ The mean value `(1.11, -1.07)` of `b_Sex` implies that female passengers have higher chance to survive than male passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPyro, we can use [Predictive](http://num.pyro.ai/en/stable/utilities.html#numpyro.infer.util.Predictive) utility for making predictions from posterior samples. Let's check how well the model performs on the training dataset. In this case, we will predict the chance to survive of each passenger (in other words, the `probs` values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'survived'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3bf5b029505b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msurvived\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"survived\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msurvived_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvived_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msurvived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msurvived\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'survived'"
     ]
    }
   ],
   "source": [
    "posterior = mcmc.get_samples().copy()\n",
    "survived = data.pop(\"survived\")\n",
    "survived_probs = Predictive(model, posterior).get_samples(random.PRNGKey(1), **data)[\"probs\"]\n",
    "((survived_probs.mean(axis=0) >= 0.5).astype(np.uint8) == survived).sum() / survived.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good result using a simple logistic regression model. Let's plot the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot uncertainty of survive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpret age vs survive; and some other factors such as class or sex..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes to the test set, which also have missing data in `Age` feature. We can't use `age_impute` from posterior samples because it is specific to the training set. So we need to marginalize them from the joint posterior distribution first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-973eb01a542b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"age_impute\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior' is not defined"
     ]
    }
   ],
   "source": [
    "posterior.pop(\"age_impute\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will use the generative model for `age`, which is `dist.Normal(age_mu, age_sigma)`, to generate missing values for the test set:\n",
    "```python\n",
    "def model(age, ...):\n",
    "    ...\n",
    "    age_isnan = onp.isnan(age)\n",
    "    age_nanidx = onp.nonzero(age_isnan)[0]\n",
    "    age_impute = numpyro.sample(\"age_impute\", dist.Normal(age_mu[age_nanidx], age_sigma[age_nanidx]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We need to perform the same data transformation process as the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posterior' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-8e7f84f33859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                  embarked=d.Embarked.astype(embarked_cat).cat.codes.values)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mposterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"age_impute\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msurvived_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurvived_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'posterior' is not defined"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/test.csv\")\n",
    "d = test_df.copy()\n",
    "d[\"Title\"] = d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).apply(\n",
    "    lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")\n",
    "test_data = dict(age=d.Age.pipe(lambda x: (x - age_mean) / age_std).values,\n",
    "                 pclass=d.Pclass.values - 1,\n",
    "                 title=d.Title.astype(title_cat).cat.codes.values,\n",
    "                 sex=(d.Sex == \"male\").astype(int).values,\n",
    "                 sibsp=d.SibSp.clip(0, 1).values,\n",
    "                 parch=d.Parch.clip(0, 2).values,\n",
    "                 embarked=d.Embarked.astype(embarked_cat).cat.codes.values)\n",
    "\n",
    "survived_probs = Predictive(model, posterior).get_samples(random.PRNGKey(2), **test_data)[\"probs\"]\n",
    "d[\"Survived\"] = (survived_probs.mean(axis=0) >= 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. McElreath, R. (2016). Statistical Rethinking: A Bayesian Course with Examples in R and Stan.\n",
    "2. Kaggle competition: [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
